<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>
    Paper recap: CutMix
  </title>
  <meta
    name="description"
    content="CutMix: Regularization Strategy to Train Strong Classifiers with Localizable FeaturesYun, Sangdoo Han, Dongyoon Chun, Sanghyuk Oh, Seong Joon Choe, Junsuk Yo..."
  />

   
  <link rel="stylesheet" href="/assets/style.css" />

  <link
    rel="canonical"
    href="https://trung-dt.com/paper-recap/2020/08/31/cutmix.html"
  />
  <link rel="alternate" type="application/rss+xml" title="Trung Dao"
  href="https://trung-dt.com/feed.xml">
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" />
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" />
  <link rel="stylesheet" href="/assets/academicons.min.css"/>
  <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
  

  <link rel="manifest" href="/site.webmanifest" />
  <script async defer src="/assets/github-buttons.js"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      extensions: [
        "MathMenu.js",
        "MathZoom.js",
        "AssistiveMML.js",
        "a11y/accessibility-menu.js"
      ],
      jax: ["input/TeX", "output/CommonHTML"],
      TeX: {
        extensions: [
          "AMSmath.js",
          "AMSsymbols.js",
          "noErrors.js",
          "noUndefined.js",
        ]
      }
    });
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      var TEX = MathJax.InputJax.TeX;
      var COLS = function (W) {
        var WW = [];
        for (var i = 0, m = W.length; i < m; i++)
          {WW[i] = TEX.Parse.prototype.Em(W[i])}
        return WW.join(" ");
      };
      TEX.Definitions.Add({
        environment: {
          psmallmatrix: ['Array',null,'(',')','c',COLS([1/3]),".2em",'S',1],
        }
      });
    });
  </script>

  <!-- Mathjax Support -->
  <script
    type="text/javascript"
    async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"
  ></script>


 <script>
  $(document).ready(function() {
    console.log("hello"); // This will print "hello" to the console if the JavaScript is running

    $('.publication').mouseover(function() {
      console.log("Mouseover event triggered");
      const video = $(this).find('video')[0]; // Get the DOM element
      console.log("Video element found:", video);
        $(video).css('display', 'block');
        $(this).find('img').css('display', 'none');
    });

    $('.publication').mouseout(function() {
      console.log("Mouseout event triggered");
      const video = $(this).find('video')[0]; // Get the DOM element
      console.log("Video element found:", video);
        $(video).css('display', 'none');
        $(this).find('img').css('display', 'block');
    });
  });
</script> 
  <script src="https://kit.fontawesome.com/a24e8ec4a3.js"></script>
</head>


  <body>
    <header class="border-bottom-thick px-2 clearfix">
  <div id="particles-js" class="particles"></div>
<script src="https://trung-dt.com/assets/particles.js/particles.js"></script>
<script src="https://trung-dt.com/assets/particles.js/dir/js/app.js"></script>

  <div class="left sm-width-full py-1 mt-1 mt-lg-0">
    <a class="align-middle link-primary text-accent" href="/">
      Trung Dao
    </a>
  </div>
  <div class="right sm-width-full">
    <ul class="list-reset right py-1 header-text font-smoothing">
   
  <li class="inline-block">
    <a
      class="align-middle link-primary header-link mr-2"
      href="/blog/"
      target="_blank"
      >üê¢ Blogs</a
    >
  </li>
    
  <li class="inline-block">
    <a
      class="align-middle link-primary header-link mr-2"
      href="/cv/"
      target="_blank"
      >üéì CV</a
    >
  </li>
    
  <li class="inline-block">
    <a
      class="align-middle link-primary header-link mr-2"
      href="/gallery/"
      target="_blank"
      >üíé Film Photos</a
    >
  </li>
         
</ul>

  </div>
</header>


    <div>
      <article
  class="container px-2 mx-auto mb4"
  itemscope
  itemtype="http://schema.org/BlogPosting"
>
  <h1
    id="post-title"
    class="h0 col-9 sm-width-full py-4 mt-3 inline-block"
    itemprop="name headline"
  >
    Paper recap: CutMix
  </h1>
  <div class="col-4 sm-width-full mt-1 border-top-thin">
    <p class="mb-3 py-2 bold h4">
      <time
        datetime="2020-08-31T00:00:00+07:00"
        itemprop="datePublished"
        >Aug 31, 2020
      </time>
      |   9 mins 
    </p>
  </div>

  <div class="prose" itemprop="articleBody">
    <h2 id="cutmix-regularization-strategy-to-train-strong-classifiers-with-localizable-features">CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features</h2>
<p><a href="https://arxiv.org/abs/1710.09412">Yun, Sangdoo Han, Dongyoon Chun, Sanghyuk Oh, Seong Joon Choe, Junsuk Yoo, Youngjoon</a></p>

<h2 id="research-topic">Research Topic</h2>
<ul>
  <li>Category (General): Deep Learning</li>
  <li>Category (Specific): Data Augmentation</li>
</ul>

<h2 id="paper-summary">Paper summary</h2>
<ul>
  <li>Introduce a new data augmentation method: CutMix, which helps:
    <ul>
      <li>Generates new samples by cutting and pasting patches within mini-batches, leading to performance boosts in many computer vision tasks.</li>
      <li>Improves the model robustness against input corruptions</li>
      <li>Performs better when facing out-of-distribution detection problems.</li>
    </ul>
  </li>
</ul>

<h2 id="explain-like-im-5-eli5-">Explain Like I‚Äôm 5 (ELI5) üë∂üë∂üë∂</h2>
<p align="center">
  <img src="/assets/images/cutmix/example.jpeg" style="width: 50%;" alt="ex" />
</p>

<h2 id="issues-addressed-by-the-paper">Issues addressed by the paper</h2>
<ul>
  <li>Regional cutout may remove informative pixels, in addition to it, these techniques also add noises by replace those cut pixels with black area.</li>
  <li>How can we maximally utilize the deleted regions, while taking advantage of better generalization and localization using regional dropout?</li>
  <li>While certainly improving classification performance, Mixup samples tend to be unnatural.</li>
  <li>Synthesizing training data guides also improves model performance, but introduces costly computations.</li>
  <li>Recently, methods adding noises to the internal features of CNNs or adding extra path to the architecture have been proposed to enhance image classification performance.</li>
  <li>Cutmix has properties such that can compensate all of those mentioned above.</li>
</ul>

<h2 id="approachmethod">Approach/Method</h2>
<ul>
  <li>Core idea: We have 2 pictures, choose a region (apply to both pictures) in the image that is proportional to the image‚Äôs ratio, then swap those regions, leads to a new sample.
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">new_image</span> <span class="o">=</span> <span class="n">MASK</span> <span class="o">*</span> <span class="n">image_1</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">MASK</span><span class="p">)</span> <span class="o">*</span> <span class="n">image_2</span>
  <span class="n">new_label</span> <span class="o">=</span> <span class="k">lambda</span> <span class="o">*</span> <span class="n">label_1</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="k">lambda</span><span class="p">)</span> <span class="o">*</span> <span class="n">label_2</span>
</code></pre></div>    </div>
  </li>
  <li><code class="language-plaintext inlined highlighter-rouge">lambda</code> is sampled from symmetric Beta distribution (having same \(\alpha\) and \(\beta\) value), which looks like the following image. This distribution makes sure that the new image will most of the time be close only to the first or the second picture. Only sometimes both images have the same intensity (of course if in a case of multicategorical, other label will be 0).</li>
</ul>

<p align="center">
  <img src="/assets/images/mixup/beta.png" style="width: 50%;" alt="lr" />
</p>

<ul>
  <li><code class="language-plaintext inlined highlighter-rouge">MASK</code> has the same WxH like the original image, having full 0s in the region that is gonna be cutout (let‚Äôs call it <code class="language-plaintext inlined highlighter-rouge">B</code>) and full 1s in the leftover pixels.</li>
  <li><code class="language-plaintext inlined highlighter-rouge">B</code> is a bounding box, having coordinates defined as \(B = (r_x, r_y, r_w, r_h)\) indicating the cropping regions.</li>
</ul>

\[r_x \sim Unif(0,W); \: r_w = W \sqrt{1 - \lambda} \\
    r_y \sim Unif(0,H); \: r_h = H \sqrt{1 - \lambda}\]

<ul>
  <li>Having these coordinates defined like this would make the cropped area ratio equals to \(1 - \lambda\).</li>
</ul>

<h2 id="result">Result</h2>
<p align="center">
  <img src="/assets/images/cutmix/compare.png" style="width: 50%;" alt="compare" />
</p>
<ul>
  <li>CutMix overcomes the problem of both Mixup (its samples tend to be unnatural) and regional cutout (removes informative pixels) by replacing the image region with a patch from another training image.</li>
  <li>CutMix incurs only negligible additional cost for training.</li>
  <li>Cutout successfully lets a model focus on less discriminative parts of the object.</li>
</ul>
<p align="center">
  <img src="/assets/images/cutmix/CAM.png" style="width: 50%;" alt="CAM" />
</p>
<ul>
  <li>Outperforms other SOTAs using data augmentation during the time of publish.</li>
</ul>
<p align="center">
  <img src="/assets/images/cutmix/result.png" style="width: 50%;" alt="result" />
</p>

<h2 id="best-practice">Best practice</h2>
<ul>
  <li>\(\alpha = 1\) usually performs well.</li>
  <li>Cutout, Mixup, and CutMix require a greater number of training epochs till convergence.</li>
  <li>CutMix achieves the best performance when it is applied on the input images rather than hidden features.</li>
  <li>A new state-of-the-art performance 13.81% (in CIFAR-100) by combining CutMix and ShakeDrop, a regularization that adds noise on intermediate features.</li>
</ul>

<h2 id="hidden-gems">Hidden gemsüíéüíéüíé</h2>
<ul>
  <li>Label-smoothing is good when apply together with data augmentation such as Cutout, Mixup, Dropblock.</li>
  <li>Mixup, Manifold Mixup achieve higher accuracies when Cutout is applied on input images.</li>
</ul>

<h2 id="conclusions">Conclusions</h2>

<h3 id="rating">Rating</h3>
<p><img src="https://media.giphy.com/media/l2JeeiVJzPmuMIRlS/giphy.gif" alt="rating" /></p>

<h2 id="paper-implementation">Paper implementation</h2>
<ul>
  <li>Using Pytorch Lightning Callback system, inspired by fastai implementation.
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">class</span> <span class="nc">MixLoss</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
      <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">old_lf</span><span class="p">,</span> <span class="n">mixup_cb</span><span class="p">):</span>
          <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
          <span class="bp">self</span><span class="p">.</span><span class="n">old_lf</span> <span class="o">=</span> <span class="n">old_lf</span>
          <span class="bp">self</span><span class="p">.</span><span class="n">mixup_cb</span> <span class="o">=</span> <span class="n">mixup_cb</span>

      <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">yb</span><span class="p">):</span>
          <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">mixup_cb</span><span class="p">.</span><span class="n">pl_module</span><span class="p">.</span><span class="n">testing</span><span class="p">:</span> <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">old_lf</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">yb</span><span class="p">)</span>
          <span class="k">with</span> <span class="n">NoneReduce</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">old_lf</span><span class="p">)</span> <span class="k">as</span> <span class="n">lf</span><span class="p">:</span>
              <span class="bp">self</span><span class="p">.</span><span class="n">mixup_cb</span><span class="p">.</span><span class="n">yb_1</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">mixup_cb</span><span class="p">.</span><span class="n">yb_1</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">pred</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
              <span class="bp">self</span><span class="p">.</span><span class="n">mixup_cb</span><span class="p">.</span><span class="n">lam</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">mixup_cb</span><span class="p">.</span><span class="n">lam</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">pred</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
              <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">lerp</span><span class="p">(</span><span class="n">lf</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">mixup_cb</span><span class="p">.</span><span class="n">yb_1</span><span class="p">),</span> <span class="n">lf</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span><span class="n">yb</span><span class="p">),</span> <span class="bp">self</span><span class="p">.</span><span class="n">mixup_cb</span><span class="p">.</span><span class="n">lam</span><span class="p">)</span>
          <span class="k">return</span> <span class="n">reduce_loss</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">old_lf</span><span class="p">,</span> <span class="s">'reduction'</span><span class="p">,</span> <span class="s">'mean'</span><span class="p">))</span>

  <span class="c1"># Cell
</span>  <span class="k">class</span> <span class="nc">CutmixDict</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
      <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.</span><span class="p">):</span>
          <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
          <span class="bp">self</span><span class="p">.</span><span class="n">distrib</span> <span class="o">=</span> <span class="n">Beta</span><span class="p">(</span><span class="n">tensor</span><span class="p">(</span><span class="n">alpha</span><span class="p">),</span> <span class="n">tensor</span><span class="p">(</span><span class="n">alpha</span><span class="p">))</span>

      <span class="k">def</span> <span class="nf">on_train_start</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">pl_module</span><span class="p">):</span>
          <span class="k">assert</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">pl_module</span><span class="p">,</span> <span class="s">'loss_func'</span><span class="p">),</span> <span class="s">'Your LightningModule should have loss_func attribute as your loss function.'</span>
          <span class="bp">self</span><span class="p">.</span><span class="n">old_lf</span> <span class="o">=</span> <span class="n">pl_module</span><span class="p">.</span><span class="n">loss_func</span>
          <span class="bp">self</span><span class="p">.</span><span class="n">loss_fnc</span> <span class="o">=</span> <span class="n">MixLoss</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">old_lf</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>
          <span class="n">pl_module</span><span class="p">.</span><span class="n">loss_func</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">loss_fnc</span>
          <span class="bp">self</span><span class="p">.</span><span class="n">pl_module</span> <span class="o">=</span> <span class="n">pl_module</span>

      <span class="k">def</span> <span class="nf">_cutmix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logger</span><span class="p">,</span> <span class="n">log_image</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">pre_fix</span><span class="o">=</span><span class="s">'train'</span><span class="p">):</span>
          <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s">"img"</span><span class="p">],</span> <span class="n">batch</span><span class="p">[</span><span class="s">"label"</span><span class="p">]</span>
          <span class="n">bs</span> <span class="o">=</span> <span class="n">yb</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
          <span class="n">W</span><span class="p">,</span> <span class="n">H</span> <span class="o">=</span> <span class="n">xb</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="n">xb</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

          <span class="n">lam</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">distrib</span><span class="p">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">1</span><span class="p">,)).</span><span class="n">squeeze</span><span class="p">()</span>
          <span class="n">lam</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">stack</span><span class="p">([</span><span class="n">lam</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">lam</span><span class="p">])</span>
          <span class="bp">self</span><span class="p">.</span><span class="n">lam</span> <span class="o">=</span> <span class="n">lam</span><span class="p">.</span><span class="nb">max</span><span class="p">()</span>

          <span class="c1"># Permute the batch
</span>          <span class="n">shuffle</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">bs</span><span class="p">)</span>
          <span class="n">xb_1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">yb_1</span> <span class="o">=</span> <span class="n">xb</span><span class="p">[</span><span class="n">shuffle</span><span class="p">],</span> <span class="n">yb</span><span class="p">[</span><span class="n">shuffle</span><span class="p">]</span>

          <span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">y2</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">rand_bbox</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">lam</span><span class="p">)</span>
          <span class="n">xb</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">x1</span><span class="p">:</span><span class="n">x2</span><span class="p">,</span> <span class="n">y1</span><span class="p">:</span><span class="n">y2</span><span class="p">]</span> <span class="o">=</span> <span class="n">xb_1</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">x1</span><span class="p">:</span><span class="n">x2</span><span class="p">,</span> <span class="n">y1</span><span class="p">:</span><span class="n">y2</span><span class="p">]</span>
          <span class="bp">self</span><span class="p">.</span><span class="n">lam</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="p">((</span><span class="n">x2</span><span class="o">-</span><span class="n">x1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y2</span><span class="o">-</span><span class="n">y1</span><span class="p">))</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">W</span><span class="o">*</span><span class="n">H</span><span class="p">))</span>

          <span class="k">if</span> <span class="n">log_image</span><span class="p">:</span>
              <span class="n">grid</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">make_grid</span><span class="p">(</span><span class="n">xb</span><span class="p">)</span>
              <span class="n">logger</span><span class="p">.</span><span class="n">experiment</span><span class="p">.</span><span class="n">add_image</span><span class="p">(</span><span class="n">pre_fix</span> <span class="o">+</span> <span class="s">'_cutmix'</span><span class="p">,</span> <span class="n">grid</span><span class="p">)</span>
              <span class="n">grid_g</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">make_grid</span><span class="p">(</span><span class="n">xb_1</span><span class="p">)</span>
              <span class="n">logger</span><span class="p">.</span><span class="n">experiment</span><span class="p">.</span><span class="n">add_image</span><span class="p">(</span><span class="n">pre_fix</span> <span class="o">+</span> <span class="s">'_cut_from'</span><span class="p">,</span> <span class="n">grid_g</span><span class="p">)</span>
              <span class="n">dif</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">xb</span> <span class="o">-</span> <span class="n">xb_1</span><span class="p">)</span>
              <span class="n">grid_d</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">make_grid</span><span class="p">(</span><span class="n">dif</span><span class="p">)</span>
              <span class="n">logger</span><span class="p">.</span><span class="n">experiment</span><span class="p">.</span><span class="n">add_image</span><span class="p">(</span><span class="n">pre_fix</span> <span class="o">+</span> <span class="s">'_dif'</span><span class="p">,</span> <span class="n">grid_d</span><span class="p">)</span>
          <span class="k">return</span> <span class="n">xb</span>

      <span class="k">def</span> <span class="nf">on_train_batch_start</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">pl_module</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">):</span>
          <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_cutmix</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">trainer</span><span class="p">.</span><span class="n">logger</span><span class="p">)</span>
          <span class="n">batch</span><span class="p">[</span><span class="s">"img"</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>

      <span class="k">def</span> <span class="nf">on_validation_start</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">pl_module</span><span class="p">):</span>
          <span class="n">pl_module</span><span class="p">.</span><span class="n">loss_func</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">old_lf</span>

      <span class="k">def</span> <span class="nf">on_validation_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">pl_module</span><span class="p">):</span>
          <span class="n">pl_module</span><span class="p">.</span><span class="n">loss_func</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">loss_fnc</span>

      <span class="k">def</span> <span class="nf">on_fit_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">pl_module</span><span class="p">):</span>
          <span class="n">pl_module</span><span class="p">.</span><span class="n">loss_func</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">old_lf</span>

      <span class="k">def</span> <span class="nf">rand_bbox</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">lam</span><span class="p">):</span>
          <span class="n">cut_rat</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">lam</span><span class="p">)</span>
          <span class="n">cut_w</span> <span class="o">=</span> <span class="p">(</span><span class="n">W</span> <span class="o">*</span> <span class="n">cut_rat</span><span class="p">).</span><span class="nb">type</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">)</span>
          <span class="n">cut_h</span> <span class="o">=</span> <span class="p">(</span><span class="n">H</span> <span class="o">*</span> <span class="n">cut_rat</span><span class="p">).</span><span class="nb">type</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">)</span>
          <span class="c1"># uniform
</span>          <span class="n">cx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,))</span>
          <span class="n">cy</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,))</span>
          <span class="n">x1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">cx</span> <span class="o">-</span> <span class="n">cut_w</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>
          <span class="n">y1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">cy</span> <span class="o">-</span> <span class="n">cut_h</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span>
          <span class="n">x2</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">cx</span> <span class="o">+</span> <span class="n">cut_w</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>
          <span class="n">y2</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">cy</span> <span class="o">+</span> <span class="n">cut_h</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span>
          <span class="k">return</span> <span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">y2</span>
</code></pre></div>    </div>
  </li>
</ul>

<h2 id="papers-needs-to-conquer-next-">Papers needs to conquer next üëèüëèüëè</h2>
<ul>
  <li>Any recommendation?</li>
</ul>

  </div>
</article>

<div class="container mx-auto px-2 py-2 clearfix">
  <!-- Use if you want to show previous and next for posts within a category. -->




<div class="col-4 sm-width-full left mr-lg-4 mt-3">
  <a
    class="no-underline border-top-thin py-1 block"
    href="https://trung-dt.com/paper-recap/2020/08/24/mixup.html"
  >
    <span class="h5 bold text-accent">Previous</span>
    <p class="bold h3 link-primary mb-1">Paper recap: MixUp: Beyond empirical risk minimization</p>
    <p>MixUp: Beyond empirical risk minimization Zhang, Hongyi Cisse, Moustapha Dauphin, Yann N.Lopez-Paz, David, 2018 Research Topic Category (General): Deep Learning...</p>
  </a>
</div>
 
<div class="col-4 sm-width-full left mt-3">
  <a
    class="no-underline border-top-thin py-1 block"
    href="https://trung-dt.com/paper-recap/2020/09/07/bagoftricks.html"
  >
    <span class="h5 bold text-accent">Next</span>
    <p class="bold h3 link-primary mb-1">Paper recap: Bag of Tricks for Image Classification with Convolutional Neural Networks</p>
    <p>## Bag of Tricks for Image Classification with Convolutional Neural Networks [He, Tong Zhang, Zhi Zhang, Hang Zhang, Zhongyue Xie,...</p>
  </a>
</div>


</div>




    </div>

    <div class="border-top-thin clearfix mt-2 mt-lg-4">
  <div class="container mx-auto px-2">
    <p class="col-8 sm-width-full left py-2 mb-0">
      2024. All rights Reserved. This website doesn't track
      you. Thanks to
      <a class="text-accent" href="https://giphy.com/">GIPHY</a> for GIFs!
    </p>
  </div>
</div>

  </body>
</html>
