---
layout: category-post
title:  "Paper recap: Cyclical Learning Rates for Training Neural Networks"
date:   2020-08-02
categories: paper-recap
---
## Cyclical Learning Rates for Training Neural Networks
[Lesli N.Smith, 2015](https://arxiv.org/abs/1506.01186)

## Explain Like I'm 5 (ELI5)
Imagine you try to draw a picture, there are multiple ways to tackle this:
- You jump straight-in, drawing up to ~80-90% of the picture. However, to refine it, you have to slow down to finish the touches, which very tiring, so you might have to slow down much more until you finish it or abandon it midway. (~ Learning rate schedule)
- You start by drawing the layout, and then you calculate how much effort you should spend on each section. After you finish one, you reevaluate again and continue to draw until the picture is done. (~Adaptive learning rate)
- You start simple, draw a tree today, draw some more trees tomorrow, and draw a sun and a mountain the following day. The gist is that you start slow and progress over time until you reach a particular intensity. Then you slow down again to avoid burnout; when you at the initial state (finish a cycle), you will do the cycle again until the picture is done. (~Cyclical Learning Rates)

## Research Topic
- Category (General): Deep Learning
- Category (Specific): Hyperparameters (Learning rate) Tuning
## Paper summary
- A new method (called Cyclical Learning Rates) for setting the learning rate, instead of monotonically decreasing it as in the traditional way allows the hyper-parameter to rise and fall systematically during training.
- CLR improves classification accuracy without tuning and does not require any computations.
- The author also showed a way to estimate the bounds for the learning rate to vary while training.
## Issues addressed by the paper
- To train a deep neural network to convergence requires one to experiment with a variety of LR.
- There are already multiple solutions to this. These include learning rate scheduling (e.g., time-based decay, step decay, exponential decay), or adaptive learning rate (e.g., RMSProp, AdaGrad, AdaDelta, Adam), but there are still some drawbacks such as:
  - Learning rate scheduling: Monotonically decreased learning rate, which later proved that it would not help the model escape from the saddle point.
  - Adaptive learning rate: requires high computational cost.
## Approach/Method
- Observation: increasing the learning rate might have a short term negative effect and yet achieve a longer-term beneficial effect. (since increasing the learning rate allows more rapid traversal of saddle point plateaus)
- Pick minimum (`base_lr`) and maximum (`max_lr`) boundaries, and the learning rate will cyclically vary between these bounds.

![Window type](/assets/images/clr/window.png)
- For the cyclical function, triangular(Bartlett) window, parabolic(Welch) window, and sinusoidal(Hanning) window produced equivalent results, which led to adopting a triangular window thanks to its simplicity.

![Triangular window](/assets/images/clr/triangular.png)

- How to find the bounds? 
  - Using "LR range test": 
    - run model for several epochs while letting the learning rate increase linearly between low and high LR values. Notice
    - Notice these 2 points:
      - When accuracy starts to increase. -> `base_lr`
      - When accuracy slows down, becomes ragged or falls down. -> `max_lr`

![LR_finder](/assets/images/clr/lr_range.png)
## Best practices
- Set `stepsize` to 2-10 times of #iterations/epoch
- Best to stop training at the end of the cycle (LR at `base_lr` and the accuracy peaks) 
  - -> Early stopping might not be good for CLR
- Optimum learning rate is usually within a factor of two of the largest one that converges, and set `base_lr` = \\(\frac{1}{3}\\) or \\(\frac{1}{4}\\)  of `max_lr`
## Results
![Result](/assets/images/clr/clr_result.png)
- `CLR` helps to model to converge much faster
- `Decay` (monotonically decreasing LR)'s result provides evidence that both increasing and decreasing LR are essential.
## Limitations
![Result](/assets/images/clr/clr_adaptive_result.png)
- When using with adaptive learning rate methods, the benefits from CLR are reduced.
## Confusing aspects of the paper
![Triangular code](/assets/images/clr/triangular_code.png)
- The variables of the code weren't explained clearly, so I redefine it here:
  - **1 epoch**: converted to #iterations (= training_size / batch_size)
  - **1 cycle**: LR goes from `base_lr` -> `max_lr` -> `base_lr`, and finish 1 epoch
  - `epochCounter`: current #iterations (e.g: 1 epoch has 2000 iters, the model's at epochs 1.5 => `epochCounter` = 3000)
  - `stepsize`: #iterations to reach 1/2 cycle (1/2 epoch)
  - `opt.LR`: current LR
  - `cycle`: which cycle the model's currently in (float), always starts from 1 (first cycle)
  - `x`: which part of the cycle, in range \[0,1\]
  - `lr`: the updated lr, with `triangular` method.
## Conclusions
### The author's conclusions
- All experiments show similar or better accuracy performance when using CLR versus using a fixed learning rate, even though the performance drops at some of the learning rate values within this range.
### Rating
Noice
### My Conclusion
- This paper is straightforward, well-explained, so I recommend new DL-practitioners to try reading it.
- CLR is an impressive technique to control the learning rate. We should try this method when we started a new model or a new dataset, giving a lovely baseline for further optimization.
- CLR is also widely used by kagglers.
### Cited references and used images from:
- https://www.jeremyjordan.me/nn-learning-rate/ 
- https://github.com/bckenstler/CLR/
### Source code/other links
- TBE